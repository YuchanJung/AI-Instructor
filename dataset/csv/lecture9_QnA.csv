Question,Answer
What are the two main fields of AI discussed in Lecture 9?,Deep Learning and Reinforcement Learning.
Why are deep neural networks described as good function approximators?,Because they can approximate a function given data.
What is the setting where deep learning methods cannot solve problems alone?,Reinforcement Learning applications.
What is Deep Q-Learning?,An algorithm that combines Q-Learning with deep learning.
"Why do we need techniques like Xavier initialization, dropout, and batch normalization?",To help deep neural networks train effectively.
What is AlphaGo and why is it significant?,"Google DeepMind's AlphaGo, which beat world champions in the game of Go using deep reinforcement learning."
"In Go, what is the goal of the game?",To maximize your territory by surrounding your opponent with stones.
What makes the board game Go more complex than chess?,The board is larger (19x19) and requires long-term strategy.
What is a major challenge in traditional supervised learning methods when applied to the game of Go?,It is hard to represent the probability of winning from a given board state.
Why are sequences of decisions important in reinforcement learning?,"Because the decisions are correlated, requiring planning ahead."
What is the key difference between RL and classic supervised learning in terms of label availability?,"RL often involves delayed labels, making it hard to use immediate feedback for learning."
What is a Q-Table in the context of Q-Learning?,A matrix storing scores for actions in every state.
What does the Bellman Equation represent in Q-Learning?,"The optimal Q-function satisfies the Bellman equation, combining immediate reward and discounted future rewards."
How does the concept of discounted return help in decision-making over long-term rewards?,"It reduces future rewards' impact over time, making the return converge."
What's a policy in reinforcement learning?,A policy is a strategy that defines the best action to take in a given state.
Why is it impractical to use Q-Tables in complex environments like the game of Go?,Because of the massive number of possible states and actions (10^170 states in Go).
How does deep learning address the limitations of using Q-Tables?,It serves as a function approximator to predict Q-values based on the state.
What is experience replay and why is it useful in reinforcement learning?,"Experience replay stores state transitions to be re-used multiple times during training, increasing data efficiency and reducing correlation."
Why is exploration important in reinforcement learning?,It helps discover new strategies that may lead to better rewards than existing known paths.
What is epsilon-greedy strategy in reinforcement learning?,A method that balances exploration and exploitation by randomly choosing an action with probability epsilon.
What is meant by 'intrinsic reward' in the context of reinforcement learning?,A reward based on exploring less-visited states to encourage curiosity and exploration.
How does the algorithm in AlphaGo combine tree search with deep learning?,It uses a value network to estimate win probabilities and a policy network to suggest actions.
What is Montezumaâ€™s Revenge and why is it challenging for reinforcement learning algorithms?,"A game requiring long sequences of correct actions, making it hard to solve with sparse rewards."
"In policy gradient methods, what is the primary objective?",To directly optimize the policy mapping states to actions.
What is the key advantage of meta learning in reinforcement learning?,It allows quick adaptation to new tasks with few gradient updates.
What is the purpose of imitation learning in reinforcement learning?,To mimic the behavior of a human expert when it is hard to define explicit rewards.
What are the key principles involved in deep reinforcement learning?,Combining deep learning (function approximation) with reinforcement learning (sequential decision-making).
How does the concept of terminal state affect the Q-Learning algorithm?,"When a terminal state is reached, the episode ends and no further future rewards are considered."
Why is preprocessing important in games like Breakout for deep reinforcement learning?,"Preprocessing reduces the input size (e.g., grayscaling, cropping) and provides history (e.g., sequence of frames) for better decision-making."
What role does stochastic gradient descent play in training deep Q-Networks?,It updates the neural network parameters by minimizing the loss between the predicted Q-values and the target values.
